# Сервис подсчета частоты слов

---

## Запуск

```
go run main.go .\War_and_Peace.txt
```

## Анализ производительности нескольких решений

Анализ производительности выполнялся командой:
```
go test -bench .
```
Вывод в test_out.txt

Решения тестировались на двух наборах данных:

- War_and_Peace.txt - файл из ТЗ
- big.txt - 100 копий файла War and Peace

---

### Single thread

- Однопоточное решение
- Читается строка из файла, затем обрабатывается в однопоточном режиме

Производительность: 
 - War_and_Peace.txt - 20.418.622 ns/op
 - big.txt - 1.923.226.800 ns/op

### Async line read

- Отдельный поток чтения
- Данные читаются строками и передаются в буфферизированный канал
- Затем данные обрабатываются одним потоком

Пороизводительность:
- War_and_Peace.txt - 19.582.434 ns/op
- big.txt - 1.812.846.000 ns/op

### Async block read

- Отдельный поток чтения
- Данные читаются блоками 4096 байт и передаются в буфферизированный канал
- Затем данные обрабатываются одним потоком

Пороизводительность:
- War_and_Peace.txt - 20.945.439 ns/op
- big.txt - 1.964.518.100 ns/op

### Async block read and multi-worker with non-shared Map

- Отдельный поток чтения
- Данные читаются блоками 4096 байт и передаются в буфферизированный канал
- Затем данные обрабатываются множеством потоков с индивидуальными мапами

Производительность:
- War_and_Peace.txt - 13.360.406 ns/op
- big.txt - 724.240.900 ns/op

## Вывод

Async block read and multi-worker with non-shared Map - самое производительное решение

Прирост в производительнсти дали:

- Многопоточная обработка данных
- Индивидуальный словарь на каждый поток обработки
- Асинхронное чтение файла блоками 4096 байт

Так же я тестировал многопоточную обработку с одним словарем, что требовало синхронизации.
С набором данных War_and_Peace.txt производительность была 33.245.523 ns/op

С набором данных bix.txt производительность была равна 1.534.235.400 ns/op
